<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>MobileNets 学习笔记</title>
<link rel="shortcut icon" href="../../assets/img/icon.png" type="image/x-icon"/>
<link rel="icon" href="../../assets/img/icon.png" type="image/x-icon"/>
<link rel="stylesheet" href="../../assets/css/github-markdown.css">
<link rel="stylesheet" href="../../assets/css/index.css">
</head>
<body class="markdown-body">
<p><a href="https://painterdrown.github.io">painterdrown Blog</a> - <a href="https://painterdrown.github.io/cv">painterdrown CV</a></p>
<h1 id="mobilenets-学习笔记"><a class="markdownIt-Anchor" href="#mobilenets-学习笔记">#</a> MobileNets 学习笔记</h1>
<blockquote>
<p>⏰ 2018-05-28 13:02:24<br/>
👨🏻‍💻 painterdrown</p>
</blockquote>
<p><ul class="markdownIt-TOC">
<li><a href="#mobilenets-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0">MobileNets 学习笔记</a>
<ul>
<li><a href="#0-abstract">0. Abstract</a></li>
<li><a href="#1-introduction">1. Introduction</a></li>
<li><a href="#2-prior-work">2. Prior Work</a></li>
<li><a href="#3-mobilenet-architecture">3. MobileNet Architecture</a>
<ul>
<li><a href="#31-depthwise-separable-convolution">3.1. Depthwise Separable Convolution</a></li>
<li><a href="#32-network-structure-and-training">3.2. Network Structure and Training</a></li>
<li><a href="#33-width-multiplier-thinner-models">3.3. Width Multiplier: Thinner Models</a></li>
<li><a href="#34-resolution-multiplier-reduced-representation">3.4. Resolution Multiplier: Reduced Representation</a></li>
</ul>
</li>
<li><a href="#4-resources">4. Resources</a></li>
</ul>
</li>
</ul>
</p>
<h2 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract">#</a> 0. Abstract</h2>
<blockquote>
<p>MobileNets are based on a streamlined architecture that uses <strong>depthwise separable convolutions</strong> to build light weight deep neural networks.</p>
</blockquote>
<p>整篇论文高频出现一组词：<strong>depthwise separable convolutions（深度可分离卷积）</strong>，这也是 MobileNets 的核心——卷积分离可以大幅度减少计算量。</p>
<h2 id="1-introduction"><a class="markdownIt-Anchor" href="#1-introduction">#</a> 1. Introduction</h2>
<p><img src="images/introduction.png" alt=""></p>
<p>目前的用于图像分类、目标识别的卷积神经网络模型，都不断地加深以及复杂化网络结构以追求更高的精度。很多现实中的应用其实对精度要求不是很苛刻，但同时又希望能做到实时的速度，特别是用于一些计算资源有限的设备上。</p>
<p>这篇论文主要介绍了 MobileNets 这个高效的网络架构，以及它的两个超参数：<strong>width multiplier</strong> &amp; <strong>resolution multiplier</strong> 来构建轻量、低延时、适用于移动设备和嵌入式设备的网络模型。</p>
<h2 id="2-prior-work"><a class="markdownIt-Anchor" href="#2-prior-work">#</a> 2. Prior Work</h2>
<p>在构建轻量高效的网络模型这一问题上，很多方法的原理基本可以分为两大类：对预训练出来的网络进行压缩 or 直接训练小网络。这篇论文将介绍如何合适地“挑选”一个小网络。</p>
<p>MobileNets 中使用 <strong>depthwise separable convolutions</strong> 的做法其实在在 Inception models 中已经有了，Flattened networks 也做过分解卷积，etc。</p>
<p>构造小网络的另外一种方法是 shrinking, factorizing or compressing pretrained networks。另外一个训练小网络的方法是 distillation（蒸馏），意思是先训练一个大网络出来，然后用这个大网络去 teach 出来一个小网络。</p>
<h2 id="3-mobilenet-architecture"><a class="markdownIt-Anchor" href="#3-mobilenet-architecture">#</a> 3. MobileNet Architecture</h2>
<p>在 MobileNets 中，核心无非是它的 <strong>depthwise separable filters</strong>，下面也将从 width multiplier &amp; resolution multiplier 两个超参数的角度来介绍其架构。</p>
<h3 id="31-depthwise-separable-convolution"><a class="markdownIt-Anchor" href="#31-depthwise-separable-convolution">#</a> 3.1. Depthwise Separable Convolution</h3>
<p>MobileNets 将标准的卷积层分解成两部分：</p>
<ol>
<li><strong>3*3 depthwise convolution</strong> 用于对输入进行过滤，输入为 $D_F · D_F · M$</li>
<li><strong>1*1 pointwise convolution</strong> 用于对过滤的结果进行结合，输出为 $D_F · D_F · N$</li>
</ol>
<p><img src="images/architecture.png" alt=""></p>
<p>原先标准卷基层的计算量是：</p>
<p>$D_K · D_K · M · N · D_F · D_F$</p>
<p>分解后的计算量为：</p>
<p>$D_K · D_K · M · D_F · D_F + M · N · D_F · D_F$</p>
<p>两者相差了 8、9 倍。</p>
<h3 id="32-network-structure-and-training"><a class="markdownIt-Anchor" href="#32-network-structure-and-training">#</a> 3.2. Network Structure and Training</h3>
<blockquote>
<p>All layers are followed by a batchnorm and ReLU nonlinearity with the exception of the final fully connected layer which has no nonlinearity and feeds into a softmax layer for classification.</p>
</blockquote>
<p>这句话的意思是说 MobileNets 中除了最后的全连接层之外，其他层都接上了 batchnorm 和 ReLU。</p>
<p><img src="images/network.png" alt=""></p>
<h3 id="33-width-multiplier-thinner-models"><a class="markdownIt-Anchor" href="#33-width-multiplier-thinner-models">#</a> 3.3. Width Multiplier: Thinner Models</h3>
<p><strong>Width Multiplier α</strong> 做的事情其实就是对输入的通道数 M 压缩成 αM。加上 width multiplier α 的 depthwise separable convolution 的计算量为：</p>
<p>$D_K · D_K · αM · D_F · D_F + αM · αN · D_F · D_F$</p>
<h3 id="34-resolution-multiplier-reduced-representation"><a class="markdownIt-Anchor" href="#34-resolution-multiplier-reduced-representation">#</a> 3.4. Resolution Multiplier: Reduced Representation</h3>
<p><strong>Resolution Multiplier ρ</strong> 做的事情是输入输出的 feature map 的尺寸进行压缩。同时加上 width multiplier α 和 resolution multiplier ρ 的 depthwise separable convolution 的计算量为：</p>
<p>$D_K · D_K · αM · ρD_F · ρD_F + αM · αN · ρD_F · ρD_F$</p>
<h2 id="4-resources"><a class="markdownIt-Anchor" href="#4-resources">#</a> 4. Resources</h2>
<ul>
<li><a href="../papers/MobileNets.pdf">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</a></li>
<li><a href="https://github.com/chuanqi305/MobileNet-SSD">chuanqi305/MobileNet-SSD（非官方）</a></li>
</ul>
</body>
</html>