[painterdrown Blog](https://painterdrown.github.io) - [painterdrown CV](https://painterdrown.github.io/cv)

# Flow-Guided Feature Aggregation for Video Object Detection å­¦ä¹ ç¬”è®°

> â° 2018-06-02 09:40:36<br/>
> ğŸ‘¨ğŸ»â€ğŸ’» painterdrown

@[toc]

## 0. Abstract

ç›®å‰çš„è§†é¢‘ç›®æ ‡æ£€æµ‹ç½‘ç»œéƒ½ä¸æ˜¯ç«¯åˆ°ç«¯çš„ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªå« flow-guided feature aggregationï¼ˆæµå¯¼å‘ç‰¹å¾èšé›†ï¼‰ï¼Œä¸€ä¸ªç«¯åˆ°ç«¯çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ŒåŠ ä¸‹æ¥æˆ‘ç®€ç§°ä¸º **FGFA**ã€‚

> It leverages temporal coherence on feature level instead.

è¿™å¥è¯çš„æ„æ€æ˜¯è¯´ï¼ŒFFA å…³æ³¨å¦‚ä½•åˆ©ç”¨ feature level çš„æ—¶é—´è¿è´¯æ€§ä¿¡æ¯ï¼Œå¹¶ä¸”åˆ©ç”¨è¿™äº›ä¿¡æ¯æ¥è¾¾åˆ°å¥½çš„æ£€æµ‹æ•ˆæœã€‚

FFA èšé›†äº†åŒä¸€è¿åŠ¨è·¯å¾„ (motion path) ä¸Šçš„ç‰¹å¾ä¿¡æ¯ã€‚

## 1. Introduction

ç›®å‰æœ€å¸…çš„å›¾åƒç›®æ ‡æ£€æµ‹æ¡†æ¶åŸºæœ¬éƒ½æ˜¯ **Deep Convolutional Neural Networks**ï¼Œä½†æ˜¯å®ƒåœ¨è§†é¢‘å¸§ä¸­è¡¨ç°æ¬ ä½³â€”â€”åŸå› æ˜¯è§†é¢‘å¸§ä¸­ *motion blur*ï¼ˆå›¾åƒè¿åŠ¨çš„åŒºåŸŸå®¹æ˜“æ¨¡ç³Šï¼‰ çš„ç°è±¡æ¯”è¾ƒæ˜æ˜¾ï¼Œè¿˜æœ‰ *video defocus*ï¼Œ*rare poses* ç­‰åŸå› ã€‚

> The performance improvement is from heuristic post-processing instead of principled learning.

ç›®å‰çš„è§†é¢‘æ£€æµ‹æ¡†æ¶ä¹Ÿæ˜¯ *box level* çš„ï¼šåœ¨æ£€æµ‹å‡ºå…³é”®å¸§ä¹‹åï¼Œåç»­çš„ bounding box æ£€æµ‹æ˜¯æ¯”è¾ƒä¼ ç»Ÿç²—æš´çš„ï¼ˆåŸºäº motion estimation æˆ–è€… optical flowï¼‰ã€‚è¿™ç§åšæ³•æ•ˆæœå¾€å¾€å¾ˆå¹³åº¸ã€‚

ä½†æ˜¯ï¼Œä¸€äº›æ¯”è¾ƒå·®çš„ feature aggregation åšæ³•ä¼šå— *video motion* çš„å½±å“ï¼ˆåŒä¸€ä¸ªç›®æ ‡åœ¨ç›¸é‚»å¸§ä¹‹é—´ç©ºé—´ä¸å¯¹é½ï¼‰ï¼Œæ‰€ä»¥æˆ‘ä»¬åº”è¯¥ç ”ç©¶å¦‚ä½•åœ¨æ·±åº¦å­¦ä¹ ä¸­æ¨¡å‹åŒ–è¿™äº› motionã€‚

![](images/architecture.png)

FGFA æ¶‰åŠäº†å››ä¸ªç½‘ç»œï¼š

+  **feature extraction network**ã€‚ç”¨æ¥æå– reference frameï¼ˆå¯ä»¥ç†è§£ä¸ºå½“å‰å¸§ï¼‰çš„ç‰¹å¾ã€‚

+ **optical flow network**ã€‚ç”¨æ¥ä¼°è®¡é‚»è¿‘å¸§ä¹‹é—´çš„è¿åŠ¨ä¿¡æ¯ã€‚ç„¶ååŸºäº reference frameï¼Œæ ¹æ®è¿™ä¸ªè¿åŠ¨ä¿¡æ¯ï¼Œå¯¹é‚»è¿‘å¸§åš warpingï¼ˆå˜å½¢ï¼‰ã€‚

+ **adaptive weighting network**ã€‚ç”¨æ¥åœ¨ reference frame çš„ feature maps ä¸Šé¢èšé›†å˜å½¢åçš„é‚»è¿‘å¸§çš„ feature mapsã€‚

+ **detection network**ã€‚èšé›†åçš„ feature maps ä¼šè¾“å…¥åˆ°è¯¥ç½‘ç»œï¼Œæ¥æ£€æµ‹ reference frame ä¸Šçš„ç›®æ ‡ã€‚

å¦å¤–ï¼ŒFGFA æ˜¯ feature level çš„ï¼Œè‹¥æ˜¯ä¸ä¸€äº› box level çš„æ–¹æ³•ç»“åˆäº’è¡¥ï¼Œå¯ä»¥æå‡æ•ˆæœã€‚

## 2. Related Work

+ **Object detection from image**ã€‚è¿™é‡Œæåˆ°äº† R-FCNï¼Œå…¶ä»–ä¸ä½œèµ˜è¿°ã€‚

+ **Object detection in video**ã€‚ImageNet æœ‰ä¸€ä¸ªæ–°çš„æ¯”èµ›å« VIDï¼Œç›®å‰å¾ˆå¤šæ–¹æ³•éƒ½æ˜¯ *bounding-box post-processing* ä¸” *multi-stage pipeline*ï¼ˆåé¢çš„ stage å¿…é¡»ä¾èµ–äºå‰é¢ stage çš„ç»“æœï¼Œè€Œä¸”ä¸å¥½åšé”™è¯¯æ ¡æ­£ï¼‰ã€‚è¿™æ­£æ˜¯ box level çš„å¼Šç«¯ï¼Œå› æ­¤ï¼ŒFGFA æ˜¯åŸºäº feature level çš„ç«¯åˆ°ç«¯ç½‘ç»œã€‚

+ **Motion estimation by flow**ã€‚è¿™é‡Œè®²çš„ä¸œè¥¿å¾ˆå¤šåœ¨ [Deep Feature Flow for Video Recognition å­¦ä¹ ç¬”è®°](https://painterdrown.github.io/cv/dff) å·²ç»æåˆ°äº†ï¼Œä¸ä½œèµ˜è¿°ã€‚

+ **Feature aggregation**ã€‚å®ƒåœ¨åŠ¨ä½œè¯†åˆ« (action recognition) ä»¥åŠè§†é¢‘æè¿° (video description) ä¸­å·²ç»è¢«å¹¿æ³›åº”ç”¨äº†ï¼Œå¤§å¤šæ•°éƒ½æ˜¯ç”¨ **RNN** æ¥èšé›†é‚»è¿‘å¸§çš„ featureã€‚æ­¤å¤–ï¼Œä¹Ÿæœ‰ä¸€äº›æ˜¯ç”¨å·ç§¯æ¥æå–æ¯”è¾ƒå…¨é¢çš„æ—¶ç©ºç‰¹å¾ (spatial-temporal features)ï¼Œä½†æ˜¯è¿™äº›å·ç§¯æ ¸ä¼šé˜»ç¢é«˜é€Ÿç§»åŠ¨ç›®æ ‡çš„ modelingã€‚ä½†æ˜¯å¦‚ä¸ºäº†æ‰“ç ´è¿™ä¸ªé™åˆ¶è€Œå•å•å¢å¤§å·ç§¯æ ¸çš„å¤§å°çš„è¯ï¼Œåˆ™ä¼šå¸¦æ¥æ¯”è¾ƒå¤šçš„è®¡ç®—å¼€é”€ã€å†…å­˜é—®é¢˜ä»¥åŠè¿‡æ‹Ÿåˆç­‰é—®é¢˜ã€‚å› æ­¤ï¼ŒFGFA ä¾é  flow-guided aggregationï¼ˆå…·æœ‰å¯ä¼¸ç¼©æ€§ï¼‰æ¥å¾—åˆ°ä¸åŒç±»å‹çš„ç›®æ ‡è¿åŠ¨ä¿¡æ¯ã€‚

+ **Visual tracking**ã€‚ç°åœ¨åŸºæœ¬éƒ½ç”¨æ·±åº¦ CNN æ¥åšç›®æ ‡è¿½è¸ªã€‚è€Œç›®æ ‡è¿½è¸ªä¸ç›®æ ‡æ£€æµ‹åˆæœ‰åŒºåˆ«ï¼šå‰è€…ä¼šå…ˆå‡è®¾ç›®æ ‡çš„åˆå§‹ä½ç½®ï¼Œä¸”ä¸è¦æ±‚åšåˆ†ç±»ã€‚

## 3. Flow Guided Feature Aggregation

### 3.1. Model Design

é¦–å…ˆï¼Œç”¨æ·±å±‚å·ç§¯è®¡ç®—å‡º reference frame I~i~ çš„ç‰¹å¾ï¼Œç„¶åé€šè¿‡ [FlowNet](../papers/FlowNet.pdf) **N~flow~** æ¥æ¨å¯¼å‡ºå…¶ neighbor frame I~j~ çš„ç‰¹å¾ï¼Œç´§æ¥ç€è¿™ä¸ªç‰¹å¾å†åšä¸€ä¸ª warpingã€‚

å¾—åˆ°ä¸€ç³»åˆ—çš„ warping åçš„ç‰¹å¾ï¼Œå°±æ‹¿æ¥åš **feature aggregation**ã€‚èšåˆåçš„ç‰¹å¾åŒ…å«äº†å¦‚ illuminations/viewpoints/poses/non-rigid ç­‰ä¿¡æ¯ã€‚

![](images/aggregation.png)

ç‰¹å¾èšé›†æ˜¯é€šè¿‡åŠ æƒç›¸åŠ å¾—åˆ°çš„ï¼Œç¦» reference frame è¶Šè¿‘çš„å¸§ï¼Œæƒé‡è¶Šå¤§ã€‚ç”¨ **cosine similarity metric** æ¥è¡¡é‡å˜æ€§åç‰¹å¾ä¸ reference frame çš„ç‰¹å¾ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚è¦æ³¨æ„çš„æ˜¯ï¼Œè®¡ç®—ç›¸ä¼¼åº¦ä¸æ˜¯ç›´æ¥ç”¨çš„ featureï¼Œè€Œæ˜¯æŠŠ feature å†ç»è¿‡ä¸€ä¸ª **tiny fully convolutional network**ï¼Œç›®çš„æ˜¯å°†ç‰¹å¾æŠ•å½±æˆä¸€ä¸ª new embeddingï¼ˆæˆ‘ä¹Ÿä¸æ‡‚æ˜¯ä»€ä¹ˆï¼‰ï¼Œè¿™æ ·èƒ½æ›´æ–¹ä¾¿åé¢çš„ç½‘ç»œå»åšç›¸ä¼¼æ€§è®¡ç®—ã€‚

### 3.2. Training and Inference

Inference çš„ä¼ªä»£ç å¦‚ä¸‹ï¼Œå¯ä»¥æè¿°ä¸ºï¼š

1. é¦–å…ˆç”¨ N~feat~ å¯¹è§†é¢‘çš„æ¯ä¸€å¸§éƒ½ç®—å‡ºå…¶å·ç§¯ç‰¹å¾å›¾
2. ä¾æ¬¡å°†æ¯ä¸€å¸§ä½œä¸º reference frameï¼Œé€šè¿‡ä¸Šè¿°çš„æ–¹æ³•ç®—å‡ºå…¶èšé›†åçš„ç‰¹å¾
3. å°†èšé›†åçš„ç‰¹å¾æ”¾è¿› N~det~ è¿›è¡Œç›®æ ‡æ£€æµ‹
4. æ›´æ–° **feature buffer**ï¼Œè¿™é‡Œå¯¹åº”ä¼ªä»£ç çš„ç¬¬ 13 è¡Œã€‚æˆ‘æ€è€ƒäº†ä¸€ä¸‹ç»ˆäºçŸ¥é“è¿™ä¸€æ­¥çš„æ„ä¹‰ï¼šç®—æ³•ä¸€å¼€å§‹çš„æ—¶å€™ï¼Œä¸æ˜¯ç›´æ¥æŠŠæ‰€æœ‰å¸§çš„ç‰¹å¾éƒ½ç®—å‡ºæ¥äº†ï¼Œå› ä¸ºé‚£æ ·å­å¤ªå å†…å­˜ã€‚å› æ­¤åªè™šå…ˆç®—å‰ K ä¸ªç‰¹å¾ï¼Œç»´æŠ¤ä¸€ä¸ªé•¿åº¦ä¸º K çš„ feature bufferã€‚åœ¨æ¯ä¸€è½®è¿­ä»£ä¹‹åï¼Œéƒ½ä¼šè®¡ç®—ä¸‹ä¸€ä¸ª feature å¡è¿› buffer é‡Œé¢ã€‚

![](images/code.png)

æ•´ä¸ª FGFA æ¶æ„æ˜¯å¯å¯¼è€Œä¸”ç«¯åˆ°ç«¯çš„ã€‚è®­ç»ƒçš„æ—¶å€™ï¼Œç”±äºå†…å­˜çš„é™åˆ¶ï¼ŒK åªèƒ½å–ä¸€ä¸ªæ¯”è¾ƒå°çš„å€¼ (K = 2)ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ª **temporal dropout** çš„è¯´æ³•ã€‚ä¸æ˜¯è¯´è®­ç»ƒçš„æ—¶å€™åªåœ¨å‰åå„ä¸¤ä¸ªé‚»è¿‘å¸§ä¹‹é—´é‡‡æ ·ï¼Œé‡‡æ ·çš„èŒƒå›´æ˜¯è·Ÿå‰é¢çš„ inference çš„èŒƒå›´ä¸€æ ·ï¼Œåªæ˜¯è®­ç»ƒçš„æ—¶å€™åªå‰åå„é‡‡æ · 2 å¸§ï¼Œæ‰€ä»¥è¿™é‡Œè¦ç†è§£å¥½ K = 2 çš„å«ä¹‰ã€‚

### 3.3. Network Architecture

+ **Flow network**: FlowNet (â€œsimpleâ€ version)
+ **Feature network**: ResNet (-50 and -101) and Inception-Resnet
+ **Embedding network**: 3 layers (randomly initialized):
  + 1Ã—1Ã—512 convolution
  + 3Ã—3Ã—512 convolution
  + 1Ã—1Ã—2048 convolution
+ **Detection network**: R-FCN

## 4. Experiments

å‚è€ƒä»¥ä¸‹ä¸¤ç¯‡è®ºæ–‡ï¼Œè®­ç»ƒçš„æ—¶å€™è¦ç”¨åˆ° ImageNet DET å’Œ VID ä¸¤ä¸ªæ•°æ®é›†ã€‚

> [T-cnn: Tubelets with convolutional neural networks for object detection from videos.](../papers/T-CNN.pdf)<br/>
> [Multi-Class Multi-Object Tracking using Changing Point Detection](../papers/Multi-Class_Multi-Object_Tracking_using_Changing_Point_Detection.pdf)

è®­ç»ƒåˆ†ä¸¤ä¸ªé˜¶æ®µï¼š
  1. ä½¿ç”¨ DET æ•°æ®é›†æ¥è®­ç»ƒ N~feat å’Œ N~det~ï¼ˆä½¿ç”¨çš„æ ‡æ³¨æ•°æ®æ˜¯ VID ä¸­çš„ 30 ä¸ªåˆ†ç±»ï¼‰ï¼Œç›¸å…³ç»†èŠ‚ï¼š
    + ä½¿ç”¨äº† SGD (one image at each mini-batch)
    + ä½¿ç”¨ 4 ä¸ª GPU æ¥è·‘ 120K æ¬¡è¿­ä»£ (each GPU holding one mini-batch)
    + The learning rates are 10^âˆ’3^ and 10^âˆ’4^ in the first 80K and in the last 40K iterations
  2. ä½¿ç”¨ VID æ•°æ®é›†æ¥è®­ç»ƒæ•´ä¸ª FGFA æ¨¡å‹ï¼Œç›¸å…³ç»†èŠ‚ï¼š
    + ä½¿ç”¨ 4 ä¸ª GPU æ¥è·‘ 60K æ¬¡è¿­ä»£
    + The learning rates are 10^âˆ’3^ and 10^âˆ’4^ in the first 40K and in the last 20K iterations

åœ¨è®­ç»ƒå’Œæµ‹è¯•çš„æ—¶å€™ï¼Œå›¾åƒä¼šè¿›è¡Œç¼©æ”¾ï¼š
  + åœ¨ N~feat~ ä¸­ï¼Œç¼©æ”¾æˆçŸ­è¾¹ä¸º 600px
  + åœ¨ N~flow~ ä¸­ï¼Œç¼©æ”¾æˆçŸ­è¾¹ä¸º 300px

## 5. Resources

+ [Flow-Guided Feature Aggregation for Video Object Detection](../papers/FGFA.pdf)
+ [GitHub (python)](https://github.com/msracver/Flow-Guided-Feature-Aggregation)
