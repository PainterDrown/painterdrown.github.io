<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>Towards High Performance Video Object Detection 学习笔记 - painterdrown Blog</title><link href='https://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,700,400&subset=latin,latin-ext' rel='stylesheet' type='text/css' /><style type='text/css'>html {overflow-x: initial !important;}#write, body { height: auto; }
#write, #write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write ol, #write p, #write ul { position: relative; }
#write, #write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p, #write pre { width: inherit; }
h1, h2, h3, h4, h5, h6, tr { break-inside: avoid; }
#write, pre { white-space: pre-wrap; }
.CodeMirror, .md-fences, table { text-align: left; }
.md-reset, a:active, a:hover { outline: 0px; }
.MathJax_SVG, .md-reset { float: none; direction: ltr; }
:root { --bg-color: #ffffff; --text-color: #333333; --select-text-bg-color: #B5D6FC; --select-text-font-color: auto; }
html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; }
body { margin: 0px; padding: 0px; bottom: 0px; top: 0px; left: 0px; right: 0px; font-size: 1rem; line-height: 1.42857143; overflow-x: hidden; background-image: inherit; background-size: inherit; background-attachment: inherit; background-origin: inherit; background-clip: inherit; background-color: inherit; background-position: inherit inherit; background-repeat: inherit inherit; }
a.url { word-break: break-all; }
.in-text-selection, ::selection { text-shadow: none; background: var(--select-text-bg-color); color: var(--select-text-font-color); }
#write { margin: 0px auto; word-break: normal; word-wrap: break-word; padding-bottom: 70px; overflow-x: visible; }
.first-line-indent #write p .md-line { text-indent: 0px; }
.first-line-indent #write li, .first-line-indent #write p, .first-line-indent #write p .md-line:first-child { text-indent: 2em; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
@media screen and (max-width: 500px) { 
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  .CodeMirror-sizer { margin-left: 0px !important; }
  .CodeMirror-gutters { display: none !important; }
}
#write > blockquote:first-child, #write > div:first-child, #write > ol:first-child, #write > p:first-child, #write > pre:first-child, #write > table:first-child, #write > ul:first-child { margin-top: 30px; }
#write li > table:first-child { margin-top: -20px; }
img { max-width: 100%; vertical-align: middle; }
button, input, select, textarea { color: inherit; font-family: inherit; font-size: inherit; font-style: inherit; font-variant-caps: inherit; font-weight: inherit; font-stretch: inherit; line-height: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
*, ::after, ::before { box-sizing: border-box; }
h1, h2, h3, h4, h5, h6 { break-after: avoid-page; orphans: 2; }
p { orphans: 4; -webkit-margin-before: 1rem; -webkit-margin-after: 1rem; -webkit-margin-start: 0px; -webkit-margin-end: 0px; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
.mathjax-block { margin-top: 0px; margin-bottom: 0px; -webkit-margin-before: 0px; -webkit-margin-after: 0px; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: 700; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.701961); color: rgb(85, 85, 85); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; cursor: pointer; }
sup.md-footnote a, sup.md-footnote a:hover { color: inherit; text-transform: inherit; text-decoration: inherit; }
.md-reset, .md-toc-item a { text-decoration: none; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; }
#write > figure:first-child { margin-top: 2em; }
figure { overflow-x: auto; margin: 1.2em 0px 0px; max-width: calc(100% + 16px); padding: 0px; }
figure > table { margin: 0px !important; }
tr { break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; }
.CodeMirror-line, .md-fences { break-inside: avoid; }
table.md-table td { min-width: 80px; }
.CodeMirror-gutters { border-right-width: 0px; background-color: inherit; margin-right: 4px; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
pre.contain-cm { white-space: normal; }
.md-fences { font-size: 0.9rem; display: block; overflow: visible; white-space: pre; background-image: inherit; background-size: inherit; background-attachment: inherit; background-origin: inherit; background-clip: inherit; background-color: inherit; position: relative !important; background-position: inherit inherit; background-repeat: inherit inherit; }
.md-diagram-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
.md-fences.mock-cm { white-space: pre-wrap; }
.show-fences-line-number .md-fences { padding-left: 0px; }
.show-fences-line-number .md-fences.mock-cm { padding-left: 40px; }
.footnotes { opacity: 0.8; font-size: 0.9rem; margin-top: 1em; margin-bottom: 1em; }
.footnotes + .footnotes { margin-top: 0px; }
.md-reset { margin: 0px; padding: 0px; border: 0px; vertical-align: top; text-shadow: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; line-height: normal; font-weight: 400; text-align: left; box-sizing: content-box; background-position: 0px 0px; background-repeat: initial initial; }
.md-toc-inner, a img, img a { cursor: pointer; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li .mathjax-block, li p { margin: 0.5rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child, li > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; white-space: normal; }
@media print { 
  body, html { border: 1px solid transparent; height: 99%; break-after: avoid-page; break-before: avoid-page; }
  #write { margin-top: 0px; border-color: transparent !important; }
  .typora-export * { -webkit-print-color-adjust: exact; }
  html.blink-to-pdf { font-size: 13px; }
  .typora-export #write { padding-left: 1cm; padding-right: 1cm; padding-bottom: 0px; break-after: avoid-page; }
  .typora-export #write::after { height: 0px; }
  @page { margin: 20mm 0px; }
}
.footnote-line { white-space: pre-wrap; margin-top: 0.714em; font-size: 0.7em; }
pre.md-meta-block { font-size: 0.8rem; min-height: 0.8rem; white-space: pre-wrap; background-color: rgb(204, 204, 204); display: block; overflow-x: hidden; background-position: initial initial; background-repeat: initial initial; }
p > img:only-child { display: block; margin: auto; }
.md-line > .md-image:only-child, p > .md-image:only-child { display: inline-block; width: 100%; text-align: center; }
.mathjax-block:not(:empty)::after, .md-toc-content::after, .md-toc::after { display: none; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.mathjax-block { white-space: pre; overflow: hidden; width: 100%; }
p + .mathjax-block { margin-top: -1.143rem; }
[contenteditable="true"]:active, [contenteditable="true"]:focus { outline: 0px; box-shadow: none; }
.md-task-list-item { position: relative; list-style-type: none; }
.task-list-item.md-task-list-item { padding-left: 0px; }
.md-task-list-item > input { position: absolute; top: 0px; left: 0px; margin-left: -1.2em; margin-top: calc(1em - 10px); }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-top-left-radius: 10px; border-top-right-radius: 10px; border-bottom-right-radius: 10px; border-bottom-left-radius: 10px; }
.MathJax_SVG, .mathjax-block .MathJax_SVG_Display { text-indent: 0px; max-width: none; max-height: none; min-height: 0px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc-item { display: block; color: rgb(65, 131, 196); }
.md-toc-inner:hover { }
.md-toc-inner { display: inline-block; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: 700; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) { 
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
code, pre, tt { font-family: var(--monospace); }
.md-comment { color: rgb(162, 127, 3); opacity: 0.8; font-family: var(--monospace); }
code { text-align: left; }
a.md-print-anchor { border: none !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: 0px !important; text-shadow: initial !important; background-position: 0px 0px !important; background-repeat: initial initial !important; }
.md-inline-math .MathJax_SVG .noError { display: none !important; }
.mathjax-block .MathJax_SVG_Display { text-align: center; margin: 1em 0px; position: relative; min-width: 100%; width: auto; display: block !important; }
.MathJax_SVG_Display, .md-inline-math .MathJax_SVG_Display { width: auto; margin: inherit; display: inline-block !important; }
.MathJax_SVG .MJX-monospace { font-family: monospace; }
.MathJax_SVG .MJX-sans-serif { font-family: sans-serif; }
.MathJax_SVG { display: inline; font-style: normal; font-weight: 400; line-height: normal; zoom: 90%; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; min-width: 0px; border: 0px; padding: 0px; margin: 0px; }
.MathJax_SVG * { transition: none; }
.os-windows.monocolor-emoji .md-emoji { font-family: "Segoe UI Symbol", sans-serif; }
.md-diagram-panel > svg, [lang="flow"] svg, [lang="mermaid"] svg { max-width: 100%; }
[lang="mermaid"] .node text { font-size: 1rem; }
table tr th { border-bottom-width: 0px; }


:root {
    --side-bar-bg-color: #fafafa;
    --control-text-color: #777;
}

@include-when-export url(https://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,700,400&subset=latin,latin-ext);

@font-face {
    font-family: 'Open Sans';
    font-style: normal;
    font-weight: normal;
    src: local('Open Sans Regular'),url('file:///Users/painterdrown/Library/Application%20Support/abnerworks.Typora/themes/github/400.woff') format('woff')
}

@font-face {
    font-family: 'Open Sans';
    font-style: italic;
    font-weight: normal;
    src: local('Open Sans Italic'),url('file:///Users/painterdrown/Library/Application%20Support/abnerworks.Typora/themes/github/400i.woff') format('woff')
}

@font-face {
    font-family: 'Open Sans';
    font-style: normal;
    font-weight: bold;
    src: local('Open Sans Bold'),url('file:///Users/painterdrown/Library/Application%20Support/abnerworks.Typora/themes/github/700.woff') format('woff')
}

@font-face {
    font-family: 'Open Sans';
    font-style: italic;
    font-weight: bold;
    src: local('Open Sans Bold Italic'),url('file:///Users/painterdrown/Library/Application%20Support/abnerworks.Typora/themes/github/700i.woff') format('woff')
}

html {
    font-size: 16px;
}

body {
    font-family: "Open Sans","Clear Sans","Helvetica Neue",Helvetica,Arial,sans-serif;
    color: rgb(51, 51, 51);
    line-height: 1.6;
}

#write{
    max-width: 860px;
  	margin: 0 auto;
  	padding: 20px 30px 40px 30px;
	padding-top: 20px;
    padding-bottom: 100px;
}
#write > ul:first-child,
#write > ol:first-child{
    margin-top: 30px;
}

body > *:first-child {
    margin-top: 0 !important;
}
body > *:last-child {
    margin-bottom: 0 !important;
}
a {
    color: #4183C4;
}
h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 1rem;
    font-weight: bold;
    line-height: 1.4;
    cursor: text;
}
h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    /*background: url("file:///Users/painterdrown/Library/Application%20Support/images/modules/styleguide/para.png") no-repeat 10px center;*/
    text-decoration: none;
}
h1 tt,
h1 code {
    font-size: inherit;
}
h2 tt,
h2 code {
    font-size: inherit;
}
h3 tt,
h3 code {
    font-size: inherit;
}
h4 tt,
h4 code {
    font-size: inherit;
}
h5 tt,
h5 code {
    font-size: inherit;
}
h6 tt,
h6 code {
    font-size: inherit;
}
h1 {
    padding-bottom: .3em;
    font-size: 2.25em;
    line-height: 1.2;
    border-bottom: 1px solid #eee;
}
h2 {
   padding-bottom: .3em;
    font-size: 1.75em;
    line-height: 1.225;
    border-bottom: 1px solid #eee;
}
h3 {
    font-size: 1.5em;
    line-height: 1.43;
}
h4 {
    font-size: 1.25em;
}
h5 {
    font-size: 1em;
}
h6 {
   font-size: 1em;
    color: #777;
}
p,
blockquote,
ul,
ol,
dl,
table{
    margin: 0.8em 0;
}
li>ol,
li>ul {
    margin: 0 0;
}
hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

body > h2:first-child {
    margin-top: 0;
    padding-top: 0;
}
body > h1:first-child {
    margin-top: 0;
    padding-top: 0;
}
body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0;
}
body > h3:first-child,
body > h4:first-child,
body > h5:first-child,
body > h6:first-child {
    margin-top: 0;
    padding-top: 0;
}
a:first-child h1,
a:first-child h2,
a:first-child h3,
a:first-child h4,
a:first-child h5,
a:first-child h6 {
    margin-top: 0;
    padding-top: 0;
}
h1 p,
h2 p,
h3 p,
h4 p,
h5 p,
h6 p {
    margin-top: 0;
}
li p.first {
    display: inline-block;
}
ul,
ol {
    padding-left: 30px;
}
ul:first-child,
ol:first-child {
    margin-top: 0;
}
ul:last-child,
ol:last-child {
    margin-bottom: 0;
}
blockquote {
    border-left: 4px solid #dfe2e5;
    padding: 0 15px;
    color: #777777;
}
blockquote blockquote {
    padding-right: 0;
}
table {
    padding: 0;
    word-break: initial;
}
table tr {
    border-top: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}
table tr:nth-child(2n),
thead {
    background-color: #f8f8f8;
}
table tr th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}
table tr td {
    border: 1px solid #dfe2e5;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}
table tr th:first-child,
table tr td:first-child {
    margin-top: 0;
}
table tr th:last-child,
table tr td:last-child {
    margin-bottom: 0;
}

.CodeMirror-gutters {
    border-right: 1px solid #ddd;
}

.md-fences,
code,
tt {
    border: 1px solid #dfe2e5;
    background-color: #f8f8f8;
    border-radius: 3px;
    padding: 0;
    font-family: Consolas, "Liberation Mono", Courier, monospace;
    padding: 2px 4px 0px 4px;
    font-size: 0.9em;
}

.md-fences {
    margin-bottom: 15px;
    margin-top: 15px;
    padding: 0.2em 1em;
    padding-top: 8px;
    padding-bottom: 6px;
}

.md-task-list-item > input {
  margin-left: -1.3em;
}

@media screen and (min-width: 914px) {
    /*body {
        width: 854px;
        margin: 0 auto;
    }*/
}
@media print {
    html {
        font-size: 13px;
    }
    table,
    pre {
        page-break-inside: avoid;
    }
    pre {
        word-wrap: break-word;
    }
}

.md-fences {
	background-color: #f8f8f8;
}
#write pre.md-meta-block {
	padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block>.code-tooltip {
	bottom: .375rem;
}

#write>h3.md-focus:before{
	left: -1.5625rem;
	top: .375rem;
}
#write>h4.md-focus:before{
	left: -1.5625rem;
	top: .285714286rem;
}
#write>h5.md-focus:before{
	left: -1.5625rem;
	top: .285714286rem;
}
#write>h6.md-focus:before{
	left: -1.5625rem;
	top: .285714286rem;
}
.md-image>.md-meta {
    /*border: 1px solid #ddd;*/
    border-radius: 3px;
    font-family: Consolas, "Liberation Mono", Courier, monospace;
    padding: 2px 0px 0px 4px;
    font-size: 0.9em;
    color: inherit;
}

.md-tag{
	color: inherit;
}

.md-toc { 
    margin-top:20px;
    padding-bottom:20px;
}

.sidebar-tabs {
    border-bottom: none;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}

/** focus mode */
.on-focus-mode blockquote {
    border-left-color: rgba(85, 85, 85, 0.12);
}

header, .context-menu, .megamenu-content, footer{
    font-family: "Segoe UI", "Arial", sans-serif;
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state{
    visibility: visible;
}

.mac-seamless-mode #typora-sidebar {
    background-color: #fafafa;
    background-color: var(--side-bar-bg-color);
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}


 .typora-export p, .typora-export .footnote-line {white-space: normal;} 
</style>
</head>
<body class='typora-export' >
<div  id='write'  class = 'is-mac'><p><a href='https://painterdrown.github.io'>painterdrown Blog</a> - <a href='https://painterdrown.github.io/cv'>painterdrown CV</a></p><h1><a name='header-n3' class='md-header-anchor '></a>Towards High Performance Video Object Detection 学习笔记</h1><blockquote><p>⏰ 2018-06-03 00:21:48<br/>
👨🏻‍💻 painterdrown</p></blockquote><div class='md-toc' mdtype='toc'><p class="md-toc-content"><span class="md-toc-item md-toc-h1" data-ref="n3"><a class="md-toc-inner" href="#header-n3">Towards High Performance Video Object Detection 学习笔记</a></span><span class="md-toc-item md-toc-h2" data-ref="n9"><a class="md-toc-inner" href="#header-n9">0. Abstract</a></span><span class="md-toc-item md-toc-h2" data-ref="n12"><a class="md-toc-inner" href="#header-n12">1. Introduction</a></span><span class="md-toc-item md-toc-h2" data-ref="n29"><a class="md-toc-inner" href="#header-n29">2. From Image to Video Object Detection</a></span><span class="md-toc-item md-toc-h3" data-ref="n48"><a class="md-toc-inner" href="#header-n48">2.1. Sparse Feature Propagation</a></span><span class="md-toc-item md-toc-h3" data-ref="n56"><a class="md-toc-inner" href="#header-n56">2.2. Dense Feature Aggregation</a></span><span class="md-toc-item md-toc-h2" data-ref="n64"><a class="md-toc-inner" href="#header-n64">3. High Performance Video Object Detection</a></span><span class="md-toc-item md-toc-h3" data-ref="n67"><a class="md-toc-inner" href="#header-n67">3.1. Sparsely Recursive Feature Aggregation</a></span><span class="md-toc-item md-toc-h3" data-ref="n86"><a class="md-toc-inner" href="#header-n86">3.2. Spatially-adaptive Partial Feature Updating</a></span><span class="md-toc-item md-toc-h3" data-ref="n104"><a class="md-toc-inner" href="#header-n104">3.3. Temporally-adaptive Key Frame Scheduling</a></span><span class="md-toc-item md-toc-h3" data-ref="n112"><a class="md-toc-inner" href="#header-n112">3.4. Inference</a></span><span class="md-toc-item md-toc-h3" data-ref="n115"><a class="md-toc-inner" href="#header-n115">3.5. Training</a></span><span class="md-toc-item md-toc-h3" data-ref="n142"><a class="md-toc-inner" href="#header-n142">3.6. Network Architecture</a></span><span class="md-toc-item md-toc-h2" data-ref="n153"><a class="md-toc-inner" href="#header-n153">4. Resources</a></span></p></div><h2><a name='header-n9' class='md-header-anchor '></a>0. Abstract</h2><p>这篇论文是基于前面 <a href='../papers/DFF.pdf'>DFF</a> 和 <a href='../papers/FGFA.pdf'>FGFA</a> 的基础之上，提出了一个旨在多帧、端到端的 feature 及 cross-frame motion 的深度学习方法。提出了三项新技术来提高稳定性，优化速度和精度，以及在两者之间做权衡。</p><h2><a name='header-n12' class='md-header-anchor '></a>1. Introduction</h2><p>之前的两项工作都有各自的缺点：<strong>DFF</strong> (Deep Feature Flow for Video Recognition) 中许多帧的特征都是由关键帧的特征传播得到的，只是一个近似的结果，存在着较大的误差（优势是速度）。<strong>FGFA</strong> (Flow-Guided Feature Aggregation for Video Object Detection) 则为了提升精度，多做了 motion estimation, feature propagation 和 aggregation，但是速度上又受限。</p><p>两者共同的主旨：motion estimation 模块放在了网络中来计算，而且整个网络框架是端到端的。</p><p>此论文要介绍的方法基于两者，效果更快、更准、更稳定。三项新技术分别是：</p><ol start='' ><li><strong>sparsely recursive feature aggregation</strong>（稀疏递归特征聚集）。这项技术用来在特征聚集时保持特征的质量，同时又减少了计算开销（与 DFF 一样，也是只对关键帧进行操作）。可以说，这项技术吸取了前面 DFF 和 FGFA 的精华，且效果优于两者。</li><li><strong>spatially-adaptive partial feature updating</strong>（空间自适应部分特征更新）。用于在非关键帧上重新计算特征（尽管传播的质量很差）。这项技术显著地提升了最终的检测精度。</li><li><strong>temporally-adaptive key frame scheduling</strong>（时间自适应关键帧调度）。之前的 DFF 是固定长度地选取关键帧（这样效果很一般），现在这项技术能预测一个关键帧的用途，即关键帧特征的质量。</li></ol><h2><a name='header-n29' class='md-header-anchor '></a>2. From Image to Video Object Detection</h2><p>现在的图像目标检测已经比较成熟，一般分两步走：</p><ol start='' ><li><p>在 ImageNet 上预训练一个全卷积网络骨架 N<sub>feat</sub>，然后进行微调</p></li><li><p>在 N<sub>feat</sub> 算出来的特征图上，做 region classification 和 bounding box regression，这个网络 N<sub>det</sub> 可分为两大类：</p><ul><li><strong>sparse object proposals（稀疏目标建议）</strong>，比如 R-CNN 系列，<a href='../papers/DCNets.pdf'>DCNets (Deformable Convolutional Networks)</a> 等</li><li><strong>dense sliding windows（稠密滑动窗口）</strong>，比如有 <a href='../papers/SSD.pdf'>SSD</a>, <a href='../papers/YOLO.pdf'>YOLO</a> 等</li></ul></li></ol><p>接下来要讲的是视频目标检测里面的两个基础方法。</p><h3><a name='header-n48' class='md-header-anchor '></a>2.1. <a href='../papers/DFF.pdf'>Sparse Feature Propagation</a></h3><p>讲的其实就是前面的 DFF，详见：</p><blockquote><p><a href='https://painterdrown.github.io/cv/fgfa'>Flow-Guided Feature Aggregation for Video Object Detection 学习笔记</a></p></blockquote><p>不过这里加了一个前缀 <strong>sparse</strong>，要理解的话应该是其是用来修饰关键帧的。因为只让关键帧进入全卷积层去算特征图，而且关键帧的数目占所有视频帧的比例比较小，因此修饰其为“稀疏”。</p><h3><a name='header-n56' class='md-header-anchor '></a>2.2. <a href='../papers/FGFA.pdf'>Dense Feature Aggregation</a></h3><p>同样的，讲的其实是上一篇的 FGFA，详见：</p><blockquote><p><a href='https://painterdrown.github.io/cv/fgfa'>Flow-Guided Feature Aggregation for Video Object Detection 学习笔记</a></p></blockquote><p>前缀 <strong>dense</strong> 应当理解为：在对 reference frame 做聚集的时候，会聚集前后 K 帧的运动信息。这里是对 reference frame 周围的所有帧都做聚集，所以说是“稠密”。</p><h2><a name='header-n64' class='md-header-anchor '></a>3. High Performance Video Object Detection</h2><p><img src='images/3tech.png' alt='' referrerPolicy='no-referrer' /></p><h3><a name='header-n67' class='md-header-anchor '></a>3.1. Sparsely Recursive Feature Aggregation</h3><blockquote><p>Exploits the complementary property and integrates the methods in DFF &amp; FGFA, both accurate and fast.</p></blockquote><p>前面 FGFA 的特征聚集，是对每个帧都做了一遍，虽说检测精度有明显提升，但是速度很慢。而且也没必要每一帧都做聚集，这样就浪费了邻近帧之间的相似信息。这里提到的新技术将只在关键帧上面做 recursive feature aggregation（递归特征聚集）。</p><p><img src='images/aggregation.png' alt='' referrerPolicy='no-referrer' /></p><p>上图是核心操作：假设我们已经聚集到了第 k 帧，接下里要聚集第 k<sup>&#39;</sup> 帧，则已经算好的中间量有：</p><ul><li>从 k 到 k<sup>&#39;</sup> 的聚集偏移量（上式右边的第一项）</li><li>第 k<sup>&#39;</sup> 帧的全卷积特征图（上式右边的第二项）</li></ul><p>两者各自与权重矩阵点乘后相加，得到第 k<sup>&#39;</sup> 帧到聚集特征。总结一下就是：第 k 帧的特征聚集了前面的帧特征，然后又传播给下一个关键帧 k<sup>&#39;</sup>。</p><h3><a name='header-n86' class='md-header-anchor '></a>3.2. Spatially-adaptive Partial Feature Updating</h3><blockquote><p>Extends the idea of adaptive feature computation from temporal domain to spatial domain, resulting in spatially-adaptive feature computation that is more effective.</p></blockquote><p>前面 DFF 的特征传播，虽说检测速度提升了不少，但是对于非关键帧的检测精度来说很差。</p><p><img src='images/propagation.png' alt='' referrerPolicy='no-referrer' /></p><p>这个式子得到的是从关键帧 k 到邻近非关键帧 i 的特征传播，不是直接的 i 的特征。所以，要得到 i 比较好的特征，就必须保证上式的这个特征传播质量。作者提出了一个新的概念来做这个事情：feature temporal consistency Q<sub>k→i</sub>。这是在 N<sub>flow</sub> 的输出层加一个 sibling branch 来做预测，得到这个值。</p><p><img src='images/consistency.png' alt='' referrerPolicy='no-referrer' /></p><p>算出 Q<sub>k→i</sub> 后，通过一个阈值 τ 来判断其是否与 i 帧相容。如果低于阈值，说明 F<sub>k→i</sub> （表示从 k 传播到 i 得到的特征）的效果不好，因此需要另外对 i 帧“打个补丁”—— updating with real feature F<sub>i</sub>(p)，也就是用卷积重新计算 i 的特征图进行更新：</p><p><img src='images/updating.png' alt='' referrerPolicy='no-referrer' /></p><p>值得注意到是，特征更新到过程是可以逐层进行的（用第 n-1 层来更新第 n 层）。</p><h3><a name='header-n104' class='md-header-anchor '></a>3.3. Temporally-adaptive Key Frame Scheduling</h3><blockquote><p>Proposes adaptive key frame scheduling that further improves the efficiency of feature computation.</p></blockquote><p>3.2 中提到的 feature temporal consistency Q<sub>k→i</sub>，我们可以用来做关键帧判断。可以这样简单的理解：如果 Q<sub>k→i</sub> 很小，说明第 k 帧与第 i 帧的相容性低，这也就说明了 i 很大概率是下一个关键帧。</p><p><img src='images/is_key.png' alt='' referrerPolicy='no-referrer' /></p><h3><a name='header-n112' class='md-header-anchor '></a>3.4. Inference</h3><p><img src='images/code.png' alt='' referrerPolicy='no-referrer' /></p><h3><a name='header-n115' class='md-header-anchor '></a>3.5. Training</h3><p>跟 FGFA 训练过程一样，由于考虑到内存问题，在 SGD 的 mini-batch 中只选取两帧（先取的作为关键帧，后取的作为非关键帧）。</p><p>在做前向的过程中：</p><ol start='' ><li>N<sub>feat</sub> 先算出关键帧 k 的特征图 F<sub>k</sub> 以及非关键帧的特征图 F<sub>i</sub></li><li>N<sub>flow</sub> 根据 F<sub>k</sub>, F<sub>i</sub> 估计出 2D flow field M<sub>i→k</sub> 以及 feature consistency indicator Q<sub>k→i</sub></li><li>根据 Q~k→i 来进行 partial feature updating 算出邻近帧（除了 i 之外的其他帧）的特征图</li><li>利用上面的 feature buffer 来做 recursive feature aggregation，对下一个关键帧进行聚集</li><li>最后把这些聚集的结果丢进 N<sub>det</sub>，得到检测结果</li></ol><p>注意一下这里的损失函数为：</p><p><img src='images/loss_function.png' alt='' referrerPolicy='no-referrer' /></p><p>式子右边第一项是 Faster R-CNN 中的损失函数 (multi-task: 同时考虑了分类和回归的效果)，右边第二项的目的是对重新计算的区域大小进行限制（训练的时候按照 1:3 的概率使 U<sub>k→i</sub> = 0/1），以提高 propagating feature 和 recomputing feature 的质量。</p><h3><a name='header-n142' class='md-header-anchor '></a>3.6. Network Architecture</h3><ul><li><strong>Flow network</strong>: FlowNet (“simple” version)</li><li><strong>Feature network</strong>: ResNet-101</li><li><strong>Detection network</strong>: R-FCN</li></ul><h2><a name='header-n153' class='md-header-anchor '></a>4. Resources</h2><ul><li><a href='../papers/Towards_High_Performance_Video_Object_Detection.pdf'>Towards High Performance Video Object Detection</a></li></ul></div>
</body>
</html>