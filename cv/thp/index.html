<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Towards High Performance Video Object Detection å­¦ä¹ ç¬”è®°</title>
<link rel="shortcut icon" href="../../assets/img/icon.png" type="image/x-icon"/>
<link rel="icon" href="../../assets/img/icon.png" type="image/x-icon"/>
<link rel="stylesheet" href="../../assets/css/github-markdown.css">
<link rel="stylesheet" href="../../assets/css/index.css">
</head>
<body class="markdown-body">
<p><a href="https://painterdrown.github.io">painterdrown Blog</a> - <a href="https://painterdrown.github.io/cv">painterdrown CV</a></p>
<h1 id="towards-high-performance-video-object-detection-å­¦ä¹ ç¬”è®°"><a class="markdownIt-Anchor" href="#towards-high-performance-video-object-detection-å­¦ä¹ ç¬”è®°">#</a> Towards High Performance Video Object Detection å­¦ä¹ ç¬”è®°</h1>
<blockquote>
<p>â° 2018-06-03 00:21:48<br/>
ğŸ‘¨ğŸ»â€ğŸ’» painterdrown</p>
</blockquote>
<p><ul class="markdownIt-TOC">
<li><a href="#towards-high-performance-video-object-detection-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0">Towards High Performance Video Object Detection å­¦ä¹ ç¬”è®°</a>
<ul>
<li><a href="#0-abstract">0. Abstract</a></li>
<li><a href="#1-introduction">1. Introduction</a></li>
<li><a href="#2-from-image-to-video-object-detection">2. From Image to Video Object Detection</a>
<ul>
<li>[2.1. <a href="../papers/DFF.pdf">Sparse Feature Propagation</a>](#21-sparse-feature-propagation)</li>
<li>[2.2. <a href="../papers/FGFA.pdf">Dense Feature Aggregation</a>](#22-dense-feature-aggregation)</li>
</ul>
</li>
<li><a href="#3-high-performance-video-object-detection">3. High Performance Video Object Detection</a>
<ul>
<li><a href="#31-sparsely-recursive-feature-aggregation">3.1. Sparsely Recursive Feature Aggregation</a></li>
<li><a href="#32-spatially-adaptive-partial-feature-updating">3.2. Spatially-adaptive Partial Feature Updating</a></li>
<li><a href="#33-temporally-adaptive-key-frame-scheduling">3.3. Temporally-adaptive Key Frame Scheduling</a></li>
<li><a href="#34-inference">3.4. Inference</a></li>
<li><a href="#35-training">3.5. Training</a></li>
<li><a href="#36-network-architecture">3.6. Network Architecture</a></li>
</ul>
</li>
<li><a href="#4-resources">4. Resources</a></li>
</ul>
</li>
</ul>
</p>
<h2 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract">#</a> 0. Abstract</h2>
<p>è¿™ç¯‡è®ºæ–‡æ˜¯åŸºäºå‰é¢ <a href="../papers/DFF.pdf">DFF</a> å’Œ <a href="../papers/FGFA.pdf">FGFA</a> çš„åŸºç¡€ä¹‹ä¸Šï¼Œæå‡ºäº†ä¸€ä¸ªæ—¨åœ¨å¤šå¸§ã€ç«¯åˆ°ç«¯çš„ feature åŠ cross-frame motion çš„æ·±åº¦å­¦ä¹ æ–¹æ³•ã€‚æå‡ºäº†ä¸‰é¡¹æ–°æŠ€æœ¯æ¥æé«˜ç¨³å®šæ€§ï¼Œä¼˜åŒ–é€Ÿåº¦å’Œç²¾åº¦ï¼Œä»¥åŠåœ¨ä¸¤è€…ä¹‹é—´åšæƒè¡¡ã€‚</p>
<h2 id="1-introduction"><a class="markdownIt-Anchor" href="#1-introduction">#</a> 1. Introduction</h2>
<p>ä¹‹å‰çš„ä¸¤é¡¹å·¥ä½œéƒ½æœ‰å„è‡ªçš„ç¼ºç‚¹ï¼š<strong>DFF</strong> (Deep Feature Flow for Video Recognition) ä¸­è®¸å¤šå¸§çš„ç‰¹å¾éƒ½æ˜¯ç”±å…³é”®å¸§çš„ç‰¹å¾ä¼ æ’­å¾—åˆ°çš„ï¼Œåªæ˜¯ä¸€ä¸ªè¿‘ä¼¼çš„ç»“æœï¼Œå­˜åœ¨ç€è¾ƒå¤§çš„è¯¯å·®ï¼ˆä¼˜åŠ¿æ˜¯é€Ÿåº¦ï¼‰ã€‚<strong>FGFA</strong> (Flow-Guided Feature Aggregation for Video Object Detection) åˆ™ä¸ºäº†æå‡ç²¾åº¦ï¼Œå¤šåšäº† motion estimation, feature propagation å’Œ aggregationï¼Œä½†æ˜¯é€Ÿåº¦ä¸Šåˆå—é™ã€‚</p>
<p>ä¸¤è€…å…±åŒçš„ä¸»æ—¨ï¼šmotion estimation æ¨¡å—æ”¾åœ¨äº†ç½‘ç»œä¸­æ¥è®¡ç®—ï¼Œè€Œä¸”æ•´ä¸ªç½‘ç»œæ¡†æ¶æ˜¯ç«¯åˆ°ç«¯çš„ã€‚</p>
<p>æ­¤è®ºæ–‡è¦ä»‹ç»çš„æ–¹æ³•åŸºäºä¸¤è€…ï¼Œæ•ˆæœæ›´å¿«ã€æ›´å‡†ã€æ›´ç¨³å®šã€‚ä¸‰é¡¹æ–°æŠ€æœ¯åˆ†åˆ«æ˜¯ï¼š</p>
<ol>
<li>
<p><strong>sparsely recursive feature aggregation</strong>ï¼ˆç¨€ç–é€’å½’ç‰¹å¾èšé›†ï¼‰ã€‚è¿™é¡¹æŠ€æœ¯ç”¨æ¥åœ¨ç‰¹å¾èšé›†æ—¶ä¿æŒç‰¹å¾çš„è´¨é‡ï¼ŒåŒæ—¶åˆå‡å°‘äº†è®¡ç®—å¼€é”€ï¼ˆä¸ DFF ä¸€æ ·ï¼Œä¹Ÿæ˜¯åªå¯¹å…³é”®å¸§è¿›è¡Œæ“ä½œï¼‰ã€‚å¯ä»¥è¯´ï¼Œè¿™é¡¹æŠ€æœ¯å¸å–äº†å‰é¢ DFF å’Œ FGFA çš„ç²¾åï¼Œä¸”æ•ˆæœä¼˜äºä¸¤è€…ã€‚</p>
</li>
<li>
<p><strong>spatially-adaptive partial feature updating</strong>ï¼ˆç©ºé—´è‡ªé€‚åº”éƒ¨åˆ†ç‰¹å¾æ›´æ–°ï¼‰ã€‚ç”¨äºåœ¨éå…³é”®å¸§ä¸Šé‡æ–°è®¡ç®—ç‰¹å¾ï¼ˆå°½ç®¡ä¼ æ’­çš„è´¨é‡å¾ˆå·®ï¼‰ã€‚è¿™é¡¹æŠ€æœ¯æ˜¾è‘—åœ°æå‡äº†æœ€ç»ˆçš„æ£€æµ‹ç²¾åº¦ã€‚</p>
</li>
<li>
<p><strong>temporally-adaptive key frame scheduling</strong>ï¼ˆæ—¶é—´è‡ªé€‚åº”å…³é”®å¸§è°ƒåº¦ï¼‰ã€‚ä¹‹å‰çš„ DFF æ˜¯å›ºå®šé•¿åº¦åœ°é€‰å–å…³é”®å¸§ï¼ˆè¿™æ ·æ•ˆæœå¾ˆä¸€èˆ¬ï¼‰ï¼Œç°åœ¨è¿™é¡¹æŠ€æœ¯èƒ½é¢„æµ‹ä¸€ä¸ªå…³é”®å¸§çš„ç”¨é€”ï¼Œå³å…³é”®å¸§ç‰¹å¾çš„è´¨é‡ã€‚</p>
</li>
</ol>
<h2 id="2-from-image-to-video-object-detection"><a class="markdownIt-Anchor" href="#2-from-image-to-video-object-detection">#</a> 2. From Image to Video Object Detection</h2>
<p>ç°åœ¨çš„å›¾åƒç›®æ ‡æ£€æµ‹å·²ç»æ¯”è¾ƒæˆç†Ÿï¼Œä¸€èˆ¬åˆ†ä¸¤æ­¥èµ°ï¼š</p>
<ol>
<li>åœ¨ ImageNet ä¸Šé¢„è®­ç»ƒä¸€ä¸ªå…¨å·ç§¯ç½‘ç»œéª¨æ¶ N<sub>feat</sub>ï¼Œç„¶åè¿›è¡Œå¾®è°ƒ</li>
<li>åœ¨ N<sub>feat</sub> ç®—å‡ºæ¥çš„ç‰¹å¾å›¾ä¸Šï¼Œåš region classification å’Œ bounding box regressionï¼Œè¿™ä¸ªç½‘ç»œ N<sub>det</sub> å¯åˆ†ä¸ºä¸¤å¤§ç±»ï¼š</li>
</ol>
<ul>
<li><strong>sparse object proposalsï¼ˆç¨€ç–ç›®æ ‡å»ºè®®ï¼‰</strong>ï¼Œæ¯”å¦‚ R-CNN ç³»åˆ—ï¼Œ<a href="../papers/DCNets.pdf">DCNets (Deformable Convolutional Networks)</a> ç­‰</li>
<li><strong>dense sliding windowsï¼ˆç¨ å¯†æ»‘åŠ¨çª—å£ï¼‰</strong>ï¼Œæ¯”å¦‚æœ‰ <a href="../papers/SSD.pdf">SSD</a>, <a href="../papers/YOLO.pdf">YOLO</a> ç­‰</li>
</ul>
<p>æ¥ä¸‹æ¥è¦è®²çš„æ˜¯è§†é¢‘ç›®æ ‡æ£€æµ‹é‡Œé¢çš„ä¸¤ä¸ªåŸºç¡€æ–¹æ³•ã€‚</p>
<h3 id="21-sparse-feature-propagation"><a class="markdownIt-Anchor" href="#21-sparse-feature-propagation">#</a> 2.1. <a href="../papers/DFF.pdf">Sparse Feature Propagation</a></h3>
<p>è®²çš„å…¶å®å°±æ˜¯å‰é¢çš„ DFFï¼Œè¯¦è§ï¼š</p>
<blockquote>
<p><a href="https://painterdrown.github.io/cv/fgfa">Flow-Guided Feature Aggregation for Video Object Detection å­¦ä¹ ç¬”è®°</a></p>
</blockquote>
<p>ä¸è¿‡è¿™é‡ŒåŠ äº†ä¸€ä¸ªå‰ç¼€ <strong>sparse</strong>ï¼Œè¦ç†è§£çš„è¯åº”è¯¥æ˜¯å…¶æ˜¯ç”¨æ¥ä¿®é¥°å…³é”®å¸§çš„ã€‚å› ä¸ºåªè®©å…³é”®å¸§è¿›å…¥å…¨å·ç§¯å±‚å»ç®—ç‰¹å¾å›¾ï¼Œè€Œä¸”å…³é”®å¸§çš„æ•°ç›®å æ‰€æœ‰è§†é¢‘å¸§çš„æ¯”ä¾‹æ¯”è¾ƒå°ï¼Œå› æ­¤ä¿®é¥°å…¶ä¸ºâ€œç¨€ç–â€ã€‚</p>
<h3 id="22-dense-feature-aggregation"><a class="markdownIt-Anchor" href="#22-dense-feature-aggregation">#</a> 2.2. <a href="../papers/FGFA.pdf">Dense Feature Aggregation</a></h3>
<p>åŒæ ·çš„ï¼Œè®²çš„å…¶å®æ˜¯ä¸Šä¸€ç¯‡çš„ FGFAï¼Œè¯¦è§ï¼š</p>
<blockquote>
<p><a href="https://painterdrown.github.io/cv/fgfa">Flow-Guided Feature Aggregation for Video Object Detection å­¦ä¹ ç¬”è®°</a></p>
</blockquote>
<p>å‰ç¼€ <strong>dense</strong> åº”å½“ç†è§£ä¸ºï¼šåœ¨å¯¹ reference frame åšèšé›†çš„æ—¶å€™ï¼Œä¼šèšé›†å‰å K å¸§çš„è¿åŠ¨ä¿¡æ¯ã€‚è¿™é‡Œæ˜¯å¯¹ reference frame å‘¨å›´çš„æ‰€æœ‰å¸§éƒ½åšèšé›†ï¼Œæ‰€ä»¥è¯´æ˜¯â€œç¨ å¯†â€ã€‚</p>
<h2 id="3-high-performance-video-object-detection"><a class="markdownIt-Anchor" href="#3-high-performance-video-object-detection">#</a> 3. High Performance Video Object Detection</h2>
<p><img src="images/3tech.png" alt=""></p>
<h3 id="31-sparsely-recursive-feature-aggregation"><a class="markdownIt-Anchor" href="#31-sparsely-recursive-feature-aggregation">#</a> 3.1. Sparsely Recursive Feature Aggregation</h3>
<blockquote>
<p>Exploits the complementary property and integrates the methods in DFF &amp; FGFA, both accurate and fast.</p>
</blockquote>
<p>å‰é¢ FGFA çš„ç‰¹å¾èšé›†ï¼Œæ˜¯å¯¹æ¯ä¸ªå¸§éƒ½åšäº†ä¸€éï¼Œè™½è¯´æ£€æµ‹ç²¾åº¦æœ‰æ˜æ˜¾æå‡ï¼Œä½†æ˜¯é€Ÿåº¦å¾ˆæ…¢ã€‚è€Œä¸”ä¹Ÿæ²¡å¿…è¦æ¯ä¸€å¸§éƒ½åšèšé›†ï¼Œè¿™æ ·å°±æµªè´¹äº†é‚»è¿‘å¸§ä¹‹é—´çš„ç›¸ä¼¼ä¿¡æ¯ã€‚è¿™é‡Œæåˆ°çš„æ–°æŠ€æœ¯å°†åªåœ¨å…³é”®å¸§ä¸Šé¢åš recursive feature aggregationï¼ˆé€’å½’ç‰¹å¾èšé›†ï¼‰ã€‚</p>
<p><img src="images/aggregation.png" alt=""></p>
<p>ä¸Šå›¾æ˜¯æ ¸å¿ƒæ“ä½œï¼šå‡è®¾æˆ‘ä»¬å·²ç»èšé›†åˆ°äº†ç¬¬ k å¸§ï¼Œæ¥ä¸‹é‡Œè¦èšé›†ç¬¬ k<sup>â€™</sup> å¸§ï¼Œåˆ™å·²ç»ç®—å¥½çš„ä¸­é—´é‡æœ‰ï¼š</p>
<ul>
<li>ä» k åˆ° k<sup>â€™</sup> çš„èšé›†åç§»é‡ï¼ˆä¸Šå¼å³è¾¹çš„ç¬¬ä¸€é¡¹ï¼‰</li>
<li>ç¬¬ k<sup>â€™</sup> å¸§çš„å…¨å·ç§¯ç‰¹å¾å›¾ï¼ˆä¸Šå¼å³è¾¹çš„ç¬¬äºŒé¡¹ï¼‰</li>
</ul>
<p>ä¸¤è€…å„è‡ªä¸æƒé‡çŸ©é˜µç‚¹ä¹˜åç›¸åŠ ï¼Œå¾—åˆ°ç¬¬ k<sup>â€™</sup> å¸§åˆ°èšé›†ç‰¹å¾ã€‚æ€»ç»“ä¸€ä¸‹å°±æ˜¯ï¼šç¬¬ k å¸§çš„ç‰¹å¾èšé›†äº†å‰é¢çš„å¸§ç‰¹å¾ï¼Œç„¶ååˆä¼ æ’­ç»™ä¸‹ä¸€ä¸ªå…³é”®å¸§ k<sup>â€™</sup>ã€‚</p>
<h3 id="32-spatially-adaptive-partial-feature-updating"><a class="markdownIt-Anchor" href="#32-spatially-adaptive-partial-feature-updating">#</a> 3.2. Spatially-adaptive Partial Feature Updating</h3>
<blockquote>
<p>Extends the idea of adaptive feature computation from temporal domain to spatial domain, resulting in spatially-adaptive feature computation that is more effective.</p>
</blockquote>
<p>å‰é¢ DFF çš„ç‰¹å¾ä¼ æ’­ï¼Œè™½è¯´æ£€æµ‹é€Ÿåº¦æå‡äº†ä¸å°‘ï¼Œä½†æ˜¯å¯¹äºéå…³é”®å¸§çš„æ£€æµ‹ç²¾åº¦æ¥è¯´å¾ˆå·®ã€‚</p>
<p><img src="images/propagation.png" alt=""></p>
<p>è¿™ä¸ªå¼å­å¾—åˆ°çš„æ˜¯ä»å…³é”®å¸§ k åˆ°é‚»è¿‘éå…³é”®å¸§ i çš„ç‰¹å¾ä¼ æ’­ï¼Œä¸æ˜¯ç›´æ¥çš„ i çš„ç‰¹å¾ã€‚æ‰€ä»¥ï¼Œè¦å¾—åˆ° i æ¯”è¾ƒå¥½çš„ç‰¹å¾ï¼Œå°±å¿…é¡»ä¿è¯ä¸Šå¼çš„è¿™ä¸ªç‰¹å¾ä¼ æ’­è´¨é‡ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªæ–°çš„æ¦‚å¿µæ¥åšè¿™ä¸ªäº‹æƒ…ï¼šfeature temporal consistency Q<sub>kâ†’i</sub>ã€‚è¿™æ˜¯åœ¨ N<sub>flow</sub> çš„è¾“å‡ºå±‚åŠ ä¸€ä¸ª sibling branch æ¥åšé¢„æµ‹ï¼Œå¾—åˆ°è¿™ä¸ªå€¼ã€‚</p>
<p><img src="images/consistency.png" alt=""></p>
<p>ç®—å‡º Q<sub>kâ†’i</sub> åï¼Œé€šè¿‡ä¸€ä¸ªé˜ˆå€¼ Ï„ æ¥åˆ¤æ–­å…¶æ˜¯å¦ä¸ i å¸§ç›¸å®¹ã€‚å¦‚æœä½äºé˜ˆå€¼ï¼Œè¯´æ˜ F<sub>kâ†’i</sub> ï¼ˆè¡¨ç¤ºä» k ä¼ æ’­åˆ° i å¾—åˆ°çš„ç‰¹å¾ï¼‰çš„æ•ˆæœä¸å¥½ï¼Œå› æ­¤éœ€è¦å¦å¤–å¯¹ i å¸§â€œæ‰“ä¸ªè¡¥ä¸â€â€”â€” updating with real feature F<sub>i</sub>Â§ï¼Œä¹Ÿå°±æ˜¯ç”¨å·ç§¯é‡æ–°è®¡ç®— i çš„ç‰¹å¾å›¾è¿›è¡Œæ›´æ–°ï¼š</p>
<p><img src="images/updating.png" alt=""></p>
<p>å€¼å¾—æ³¨æ„åˆ°æ˜¯ï¼Œç‰¹å¾æ›´æ–°çš„è¿‡ç¨‹æ˜¯å¯ä»¥é€å±‚è¿›è¡Œçš„ï¼ˆç”¨ç¬¬ n-1 å±‚æ¥æ›´æ–°ç¬¬ n å±‚ï¼‰ã€‚</p>
<h3 id="33-temporally-adaptive-key-frame-scheduling"><a class="markdownIt-Anchor" href="#33-temporally-adaptive-key-frame-scheduling">#</a> 3.3. Temporally-adaptive Key Frame Scheduling</h3>
<blockquote>
<p>Proposes adaptive key frame scheduling that further improves the efficiency of feature computation.</p>
</blockquote>
<p>3.2 ä¸­æåˆ°çš„ feature temporal consistency Q<sub>kâ†’i</sub>ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨æ¥åšå…³é”®å¸§åˆ¤æ–­ã€‚å¯ä»¥è¿™æ ·ç®€å•çš„ç†è§£ï¼šå¦‚æœ Q<sub>kâ†’i</sub> å¾ˆå°ï¼Œè¯´æ˜ç¬¬ k å¸§ä¸ç¬¬ i å¸§çš„ç›¸å®¹æ€§ä½ï¼Œè¿™ä¹Ÿå°±è¯´æ˜äº† i å¾ˆå¤§æ¦‚ç‡æ˜¯ä¸‹ä¸€ä¸ªå…³é”®å¸§ã€‚</p>
<p><img src="images/is_key.png" alt=""></p>
<h3 id="34-inference"><a class="markdownIt-Anchor" href="#34-inference">#</a> 3.4. Inference</h3>
<p><img src="images/code.png" alt=""></p>
<h3 id="35-training"><a class="markdownIt-Anchor" href="#35-training">#</a> 3.5. Training</h3>
<p>è·Ÿ FGFA è®­ç»ƒè¿‡ç¨‹ä¸€æ ·ï¼Œç”±äºè€ƒè™‘åˆ°å†…å­˜é—®é¢˜ï¼Œåœ¨ SGD çš„ mini-batch ä¸­åªé€‰å–ä¸¤å¸§ï¼ˆå…ˆå–çš„ä½œä¸ºå…³é”®å¸§ï¼Œåå–çš„ä½œä¸ºéå…³é”®å¸§ï¼‰ã€‚</p>
<p>åœ¨åšå‰å‘çš„è¿‡ç¨‹ä¸­ï¼š</p>
<ol>
<li>N<sub>feat</sub> å…ˆç®—å‡ºå…³é”®å¸§ k çš„ç‰¹å¾å›¾ F<sub>k</sub> ä»¥åŠéå…³é”®å¸§çš„ç‰¹å¾å›¾ F<sub>i</sub></li>
<li>N<sub>flow</sub> æ ¹æ® F<sub>k</sub>, F<sub>i</sub> ä¼°è®¡å‡º 2D flow field M<sub>iâ†’k</sub> ä»¥åŠ feature consistency indicator Q<sub>kâ†’i</sub></li>
<li>æ ¹æ® Q~kâ†’i æ¥è¿›è¡Œ partial feature updating ç®—å‡ºé‚»è¿‘å¸§ï¼ˆé™¤äº† i ä¹‹å¤–çš„å…¶ä»–å¸§ï¼‰çš„ç‰¹å¾å›¾</li>
<li>åˆ©ç”¨ä¸Šé¢çš„ feature buffer æ¥åš recursive feature aggregationï¼Œå¯¹ä¸‹ä¸€ä¸ªå…³é”®å¸§è¿›è¡Œèšé›†</li>
<li>æœ€åæŠŠè¿™äº›èšé›†çš„ç»“æœä¸¢è¿› N<sub>det</sub>ï¼Œå¾—åˆ°æ£€æµ‹ç»“æœ</li>
</ol>
<p>æ³¨æ„ä¸€ä¸‹è¿™é‡Œçš„æŸå¤±å‡½æ•°ä¸ºï¼š</p>
<p><img src="images/loss_function.png" alt=""></p>
<p>å¼å­å³è¾¹ç¬¬ä¸€é¡¹æ˜¯ Faster R-CNN ä¸­çš„æŸå¤±å‡½æ•° (multi-task: åŒæ—¶è€ƒè™‘äº†åˆ†ç±»å’Œå›å½’çš„æ•ˆæœ)ï¼Œå³è¾¹ç¬¬äºŒé¡¹çš„ç›®çš„æ˜¯å¯¹é‡æ–°è®¡ç®—çš„åŒºåŸŸå¤§å°è¿›è¡Œé™åˆ¶ï¼ˆè®­ç»ƒçš„æ—¶å€™æŒ‰ç…§ 1:3 çš„æ¦‚ç‡ä½¿ U<sub>kâ†’i</sub> = 0/1ï¼‰ï¼Œä»¥æé«˜ propagating feature å’Œ recomputing feature çš„è´¨é‡ã€‚</p>
<h3 id="36-network-architecture"><a class="markdownIt-Anchor" href="#36-network-architecture">#</a> 3.6. Network Architecture</h3>
<ul>
<li><strong>Flow network</strong>: FlowNet (â€œsimpleâ€ version)</li>
<li><strong>Feature network</strong>: ResNet-101</li>
<li><strong>Detection network</strong>: R-FCN</li>
</ul>
<h2 id="4-resources"><a class="markdownIt-Anchor" href="#4-resources">#</a> 4. Resources</h2>
<ul>
<li><a href="../papers/Towards_High_Performance_Video_Object_Detection.pdf">Towards High Performance Video Object Detection</a></li>
</ul>
</body>
</html>